{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from os.path import dirname, join as pjoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 50, 129)\n"
     ]
    }
   ],
   "source": [
    "HRTFdata = namedtuple('HRTF',['sid','HRIR_L','HRIR_R','HRTF_L','HRTF_R','ITD','DTF_L','DTF_R','DTF2_L','DTF2_R'])\n",
    "HRTFdata_full=[]\n",
    "\n",
    "# Define parameters\n",
    "fs = 44100\n",
    "Nbases = [1,5,10,20,30,50,75,100,128]   # number of bases to be selected from\n",
    "N = 256; # FFT length\n",
    "\n",
    "# load data\n",
    "names=os.listdir('C:/Users/root/Documents/00phd/00ThirdPartyCode/ForSignalProcessing/SOFA API/SOFA API for Matlab and Octave 1.1.1/HRTFs/CIPIC_hrtf_database/standard_hrir_database/')\n",
    "# print(names)\n",
    "# column_names=['id','elevation','azimuth','hrtf']\n",
    "# input=pd.DataFrame(columns=column_names)\n",
    "# input.id=names[1:]\n",
    "# print(input)\n",
    "\n",
    "for i in range(1, len(names)-1):  # You can replace 3 with the number of subjects you have\n",
    "    data_dir = pjoin('C:/Users/root/Documents/00phd/00ThirdPartyCode/ForSignalProcessing/SOFA API/SOFA API for Matlab and Octave 1.1.1/HRTFs/CIPIC_hrtf_database/standard_hrir_database/', names[i])\n",
    "    mat_fname = pjoin(data_dir, 'hrir_final.mat')\n",
    "    data=sio.loadmat(mat_fname)\n",
    "    sid = names[i]\n",
    "    HRIR_L=data.get('hrir_l')\n",
    "    HRIR_R=data.get('hrir_r')\n",
    "    HRTF_L=scipy.fft.rfft(HRIR_L,N)\n",
    "    HRTF_R=scipy.fft.rfft(HRIR_R,N)\n",
    "    ITD=data.get('ITD')\n",
    "    DTF_L=np.zeros(HRTF_L.shape)\n",
    "    DTF_R=np.zeros(HRTF_L.shape)\n",
    "    DTF2_L=np.zeros(HRTF_L.shape)\n",
    "    DTF2_R=np.zeros(HRTF_L.shape)\n",
    "\n",
    "    # Append data as to the list\n",
    "    HRTFdata_full.append(HRTFdata(sid,HRIR_L,HRIR_R,HRTF_L,HRTF_R,ITD,DTF_L,DTF_R,DTF2_L,DTF2_R))\n",
    "\n",
    "print(HRTFdata_full[4].DTF_L.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    }
   ],
   "source": [
    "print(len(HRTFdata_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\root\\AppData\\Local\\Temp\\ipykernel_19936\\2862158546.py:10: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  meanHRTF_L[i][j] = sum_L / (HRTFdata_full[0].HRTF_L.shape[0]*HRTFdata_full[0].HRTF_L.shape[1])\n",
      "C:\\Users\\root\\AppData\\Local\\Temp\\ipykernel_19936\\2862158546.py:11: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  meanHRTF_R[i][j] = sum_R / (HRTFdata_full[0].HRTF_L.shape[0]*HRTFdata_full[0].HRTF_L.shape[1])\n",
      "C:\\Users\\root\\AppData\\Local\\Temp\\ipykernel_19936\\2862158546.py:13: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  HRTFdata_full[i].DTF_L[:,:,j] = np.divide(HRTFdata_full[i].HRTF_L[:,:,j], meanHRTF_L[i][j])    # element-wise division\n",
      "C:\\Users\\root\\AppData\\Local\\Temp\\ipykernel_19936\\2862158546.py:14: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  HRTFdata_full[i].DTF_R[:,:,j] = np.divide(HRTFdata_full[i].HRTF_R[:,:,j], meanHRTF_R[i][j])\n"
     ]
    }
   ],
   "source": [
    "meanHRTF_L=np.zeros((len(HRTFdata_full),HRTFdata_full[0].HRTF_L.shape[2]))\n",
    "meanHRTF_R=np.zeros((len(HRTFdata_full),HRTFdata_full[0].HRTF_L.shape[2]))\n",
    "\n",
    "# Compute DTF and DTF2\n",
    "for i in range(0, len(HRTFdata_full)): # for each subject\n",
    "    for j in range(0, HRTFdata_full[0].DTF_L.shape[2]): # for each fft bin\n",
    "        sum_L = np.sum(HRTFdata_full[i].HRTF_L.take(indices=j,axis=2), axis=(0,1)) # unweighted by IID\n",
    "        sum_R = np.sum(HRTFdata_full[i].HRTF_R.take(indices=j,axis=2), axis=(0,1))\n",
    "\n",
    "        meanHRTF_L[i][j] = sum_L / (HRTFdata_full[0].HRTF_L.shape[0]*HRTFdata_full[0].HRTF_L.shape[1])\n",
    "        meanHRTF_R[i][j] = sum_R / (HRTFdata_full[0].HRTF_L.shape[0]*HRTFdata_full[0].HRTF_L.shape[1])\n",
    "        \n",
    "        HRTFdata_full[i].DTF_L[:,:,j] = np.divide(HRTFdata_full[i].HRTF_L[:,:,j], meanHRTF_L[i][j])    # element-wise division\n",
    "        HRTFdata_full[i].DTF_R[:,:,j] = np.divide(HRTFdata_full[i].HRTF_R[:,:,j], meanHRTF_R[i][j])\n",
    "        \n",
    "#    subj.meanHRTF(i) = (subj.meanHRTF_l(i)+subj.meanHRTF_r(i)) / 2; # in case u need it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    }
   ],
   "source": [
    "print(len(HRTFdata_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yuqing23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
